{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "TP_Test-CHPS0703.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIoy3GA9Ao8b"
      },
      "source": [
        "# TP Test CHPS0703"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fxwDlnYAo8b"
      },
      "source": [
        "In this assessment, you will train a new neural networks model that is able to recognize fresh and rotten fruit. \n",
        "\n",
        "The grade will be depend on the validation accuracy of the model you train, as follows:\n",
        "- 90% accuracy --> 10/20\n",
        "- 91% --> 11/20\n",
        "- 92% --> 12/20\n",
        "- ..\n",
        "- 100% accuracy --> 20/20\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDv7PGQ0KsST"
      },
      "source": [
        "# BEFORE STARTING!!!!\n",
        "\n",
        "## Change the execution mode to \"GPU\"\n",
        "--> \"Exécution\"->\"Modifier le type d'exécution\"->Accélération matérielle : GPU\"\n",
        "\n",
        "Without this, your training phase will be **painfully slow**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1wKbManAo8c"
      },
      "source": [
        "## The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hrKaTztAo8c"
      },
      "source": [
        "In this exercise, you will train a model to recognize fresh and rotten fruits. The dataset comes from [Kaggle](https://www.kaggle.com/sriramr/fruits-fresh-and-rotten-for-classification), a great place to go if you're interested in starting a project after this class. The dataset structure is in the `data/fruits` folder. There are 6 categories of fruits: fresh apples, fresh oranges, fresh bananas, rotten apples, rotten oranges, and rotten bananas. This will mean that your model will require an output layer of 6 neurons to do the categorization successfully. You'll also need to compile the model with `categorical_crossentropy`, as we have more than two categories.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ROxY9mPB6tR"
      },
      "source": [
        "!wget http://urca.lsteffenel.fr/fruits.zip -O fruits.zip\n",
        "!unzip fruits.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4sUYRwnAo8d"
      },
      "source": [
        "## Load ImageNet Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuTwh6TdAo8d"
      },
      "source": [
        "We encourage you to start with a model pretrained on ImageNet. Load the model with the correct weights, set an input shape, and choose to remove the last layers of the model. Remember that images have three dimensions: a height, and width, and a number of channels. Because these pictures are in color, there will be three channels for red, green, and blue. We've filled in the input shape for you. This cannot be changed or the assessment will fail. If you need a reference for setting up the pretrained model, please take a look at `presidential_doggy_door` exercice where we implemented transfer learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqPGNqo2Ao8d"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hora_EE8Ao8e"
      },
      "source": [
        "## Freeze Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVHxsszYAo8f"
      },
      "source": [
        "Next, we suggest freezing the base model. This is done so that all the learning from the ImageNet dataset does not get destroyed in the initial training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0W-gUqcAo8f"
      },
      "source": [
        "# Freeze base model\n",
        "base_model.trainable = FIXME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK5PoFvZAo8f"
      },
      "source": [
        "## Add Layers to Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAepz6qCAo8f"
      },
      "source": [
        "Now it's time to add layers to the pretrained model. Again, the `presidential_doggy_door` example can be used as a guide. Pay close attention to the last dense layer and make sure it has the correct number of neurons to classify the different types of fruit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F11365ceAo8g"
      },
      "source": [
        "# Create inputs with correct shape\n",
        "inputs = FIXME\n",
        "\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# Add pooling layer or flatten layer\n",
        "x = FIXME\n",
        "\n",
        "# Add final dense layer\n",
        "outputs = keras.layers.Dense(FIXME, activation = 'softmax')(x)\n",
        "\n",
        "# Combine inputs and outputs to create model\n",
        "model = keras.Model(FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN8FQiXDAo8g"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_3zaCp9Ao8h"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ys4EXd9Ao8h"
      },
      "source": [
        "Now it's time to compile the model with loss and metrics options. Remember that we're training on a number of different categories, rather than a binary classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp7LRB0ZAo8i"
      },
      "source": [
        "model.compile(loss = FIXME , metrics = FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLDNaF3tAo8i"
      },
      "source": [
        "## Augment the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWC-ZSGrAo8i"
      },
      "source": [
        "Try to augment the data to improve the dataset. Feel free to look at `asl_augmentation` and `presidential_doggy_door` for augmentation examples. There is also documentation for the [Keras ImageDataGenerator class](https://keras.io/api/preprocessing/image/#imagedatagenerator-class). This step may be helpful to get to 92% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyPFKQrUAo8j"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGk3SGIzAo8j"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEhmlgffAo8j"
      },
      "source": [
        "Now it's time to load the train and validation datasets. Pick the right folders, as well as the right `target_size` of the images (it needs to match the height and width input of the model you've created). If you'd like a reference, you can check out `presidential_doggy_door`."
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "cb_f4eALAo8j"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9ZNq-ftAo8k"
      },
      "source": [
        "# load and iterate training dataset\n",
        "train_it = datagen.flow_from_directory(FIXME, \n",
        "                                       target_size=FIXME, \n",
        "                                       color_mode='rgb', \n",
        "                                       class_mode=\"categorical\")\n",
        "# load and iterate validation dataset\n",
        "valid_it = datagen.flow_from_directory(FIXME, \n",
        "                                      target_size=FIXME, \n",
        "                                      color_mode='rgb', \n",
        "                                      class_mode=\"categorical\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmRfEtx0Ao8k"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIxU3yvrAo8k"
      },
      "source": [
        "Time to train the model! Pass the `train` and `valid` iterators into the `fit` function, as well as setting your desired number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrxVSQ9uAo8k"
      },
      "source": [
        "model.fit(FIXME,\n",
        "          validation_data=FIXME,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZM7itCtAo8l"
      },
      "source": [
        "## Unfreeze Model for Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYvGcRfRAo8l"
      },
      "source": [
        "If you have reached 90% validation accuracy already, this next step is optional. If not, we suggest fine tuning the model with a very low learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VmXQPILAo8l"
      },
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = FIXME\n",
        "\n",
        "# Compile the model with a low learning rate\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = FIXME),\n",
        "              loss = FIXME , metrics = FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYsk-vBDAo8l"
      },
      "source": [
        "model.fit(FIXME,\n",
        "          validation_data=FIXME,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=FIXME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1vDutxqAo8m"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNBkhf5gAo8m"
      },
      "source": [
        "Hopefully, you now have a model that has a validation accuracy of 90% or higher. If not, you may want to go back and either run more epochs of training, or adjust your data augmentation. \n",
        "\n",
        "Once you are satisfied with the validation accuracy, evaluate the model by executing the following cell. The evaluate function will return a tuple, where the first value is your loss, and the second value is your accuracy. To pass, the model will need have an accuracy value of `90% or higher`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxw4LyU6Ao8m"
      },
      "source": [
        "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJhuoYugAo8n"
      },
      "source": [
        "## Enter your name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBn-pOhsIHBt"
      },
      "source": [
        "# Prénom NOM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unZZdPZ0Ao8n"
      },
      "source": [
        "After entering your name in the field above, **export the notebook**(Fichier->Télécharger->Télécharger le fichier .ipynb) and upload it at the dedicated space in `Bureau Virtuel`."
      ]
    }
  ]
}